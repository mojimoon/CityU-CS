# Performance Analysis Exercise

## Q1: L1 Cache

Assume the CPI of a computer is 1.0.

- 30% of the instructions access memory.
- CPU has L1 instruction and data cache, hit rate = 95%.
- Main memory access time = 100c.

Calculate:

1. The speedup of using L1 cache compared to not using cache.
2. The speedup of all cache hits compared to the given hit rate.

### Solution

1. If not using cache,

- The overhead of each instruction is $100c$.
- The overhead of data access is $0.3 \times 100c = 30c$.
- Total time = $100c + 30c + 1c = 131c$.

If using cache,

- The overhead of each instruction is $0.95 \times 0 + 0.05 \times 100c = 5c$.
- The overhead of data access is $0.3 \times (0.95 \times 0 + 0.05 \times 100c) = 1.5c$.
- Total time = $5c + 1.5c + 1c = 7.5c$.

Speedup = $\frac{131c}{7.5c} = 17.47$.

2. If all cache hits, there will be no overhead. Total time = $1c$.

Speedup = $\frac{7.5c}{1c} = 7.5$.

## Q2: L1 Cache

Assume the CPI of a computer is 1.0.

- 15% of the instructions access memory.
- CPU has L1 instruction cache, hit rate = 99%.
- CPU has L1 data cache, hit rate = $p$.
- Main memory access time = 100c.

The overall CPI of the computer is 3.2. Determine the value of $p$.

### Solution

- The overhead of each instruction is $0.99 \times 0 + 0.01 \times 100c = c$.
- The overhead of data access is $0.15 \times (p \times 0 + (1 - p) \times 100c) = (15-15p)c$.
- Total time = $c + (15-15p)c + 1c = (17-15p)c = 3.2c$.

Solution: $p = 0.92$.

## Q3: L2 Cache

Assume the CPI of a computer is 1.0.

- 20% of the instructions access memory.
- CPU has L1 instruction and data cache, both hit rate = 95%.
- CPU has L2 cache, hit rate = 99%.
- Access time of L2 cache = 10c.
- Main memory access time = 100c.

1. What is the speedup of doubling the memory access speed?
2. Which of the cache plays a more important role in improving performance?

### Solution

1. Under the current configuration,
- The overhead of each instruction is $0.95 \times 0 + 0.05 \times 10c + 0.05 \times 0.01 \times 100c = 0.55c$.
- The overhead of data access is $0.20 \times 0.55c = 0.11c$.
- Total time = $0.55c + 0.11c + 1c = 1.66c$.

If doubling the memory access speed,
- The overhead of each instruction is $0.95 \times 0 + 0.05 \times 10c + 0.05 \times 0.01 \times 50c = 0.525c$.
- The overhead of data access is $0.20 \times 0.525c = 0.105c$.
- Total time = $0.525c + 0.105c + 1c = 1.63c$.

Speedup = $\frac{1.66c}{1.63c} = 1.02$.

2. Consider removing L2 cache,
- The overhead of each instruction is $0.95 \times 0 + 0.05 \times 100c = 5c$.
- The overhead of data access is $0.20 \times 5c = 1c$.
- Total time = $5c + 1c + 1c = 7c$.

Consider removing L1 cache,
- The overhead of each instruction is $1.00 \times 10c + 0.01 \times 100c = 11c$.
- The overhead of data access is $0.20 \times 11c = 2.2c$.
- Total time = $11c + 2.2c + 1c = 14.2c$.

Therefore, L1 cache plays a more important role in improving performance.

## Q5: Multicore

Assume in a program,
- 80% of the instructions are independent.
- 10% can be parallelized on at most 4 cores.
- 10% must be executed sequentially.

What is the speedup of using 8 cores compared to single core?

### Solution

The single core execution time = $1.0$.

The 8-core execution time = $\frac{0.8}{8} + \frac{0.1}{4} + 0.1 = 0.225$.

Speedup = $\frac{1.0}{0.225} = 4.44$.

## Q6: Multicore

Assume in a program,
- 40% of the instructions are independent.
- 40% can be parallelized on at most 8 cores.
- 10% can be parallelized on at most 4 cores.
- 10% must be executed sequentially.

Calculate the minimum number of cores to achieve a speedup of (1) 4.0, (2) 8.0.

### Solution

When $n \leq 4$, execution time = $\frac{0.4}{n} + \frac{0.4}{n} + \frac{0.1}{n} + 0.1 = \frac{0.9}{n} + 0.1$.

When $4 < n \leq 8$, execution time = $\frac{0.4}{n} + \frac{0.4}{n} + \frac{0.1}{4} + 0.1 = \frac{0.8}{n} + 0.125$.

When $n > 8$, execution time = $\frac{0.4}{n} + \frac{0.4}{8} + \frac{0.1}{4} + 0.1 = \frac{0.4}{n} + 0.175$.

(1) When speedup = 4.0, execution speed = $\frac{1}{4.0} = 0.25$. Solve the equation $\frac{0.8}{n} + 0.125 = 0.25$, result is $n = 6.4$, which means at least 7 cores are needed.

(2) When speedup = 8.0, execution speed = $\frac{1}{8.0} = 0.125$. Since $\lim_{n \to \infty} \frac{0.4}{n} + 0.175 = 0.175$, a speedup of 8.0 can never be achieved.

## Q7: From Past Paper

Consider a program consisting of $10^7$ instructions.

- 20% of the instructions access the data memory.
- CPU has L1 instruction cache, hit rate = 99%.
- CPU has L1 data cache, hit rate = 95%.
- Main memory access time = 100c.

Compute the total number of:

1. Average occurrences of memory access per instruction.
2. The number of memory cycle stalls over the execution of the program.

### Solution

1. $1 \times (1 - 0.99) + 0.2 \times (1 - 0.95) = 0.02$.
2. $[1 \times (1 - 0.99) + 0.2 \times (1 - 0.95)] \times 100 \times 10^7 = 2 \times 10^7$.

## Selected Problems from 21/22 Sem A Final Exam

### Q9

In DMA transfers, the required signals and addresses are issued by the ().

1. processor / 2. device drivers / 3. DMA controller / 4. main memory

Solution: 3

Note that the CPU only tells the DMA controller to start the transfer, with extra parameters (the memory address to store the data, the size of the data, etc.). The DMA controller will then communicate with the device driver and the device to complete the transfer.

### Q17

Suppose two CPU A and B have exactly the same circuits, but different clock frequencies.
1. If the clock frequency of CPU A is 8 MHz, how long is a clock cycle?
2. If the CPU A can execute 0.4 million instructions per second, what is the average execution time of each instruction?
3. What is the CPI of CPU A?
4. If the clock frequency of CPU B is 12 MHz, how many instructions can CPU B execute per second? What is the CPI of CPU B?
5. In reality, instruction per second of CPU B is lower than the computed value in (4). Give one possible reason.

Solution:

1. $1 / (8 \times 10^6) = 0.125 \mu s$.
2. $1 / (0.4 \times 10^6) = 2.5 \mu s$.
3. $2.5 \mu s / 0.125 \mu s = 20$.
4. $\frac{12 \times 10^6}{8 \times 10^6} \times 0.4 \times 10^6 = 0.6 \times 10^6$. CPI = 20.
5. A higher clock frequency means a shorter clock cycle, so the pipeline is more likely to be stalled.

### Q21

Consider a 3-bit carry lookahead adder. Please use $A_2, A_1, A_0, B_2, B_1, B_0, C_0$ to express all the intermediate values and outputs in the adder.

Solution:

- $G_0 = A_0 \cdot B_0$
- $P_0 = A_0 + B_0$
- $G_1 = A_1 \cdot B_1$
- $P_1 = A_1 + B_1$
- $G_2 = A_2 \cdot B_2$
- $P_2 = A_2 + B_2$
- $S_0 = P_0 \oplus C_0 = (A_0 + B_0) \oplus C_0$
- $S_1 = P_1 \oplus C_1 = (A_1 + B_1) \oplus [A_0 \cdot B_0 + (A_0 + B_0) \cdot C_0]$
- $S_2 = P_2 \oplus C_2 = (A_2 + B_2) \oplus [A_1 \cdot B_1 + (A_1 + B_1) \cdot A_0 \cdot B_0 + (A_1 + B_1) \cdot (A_0 + B_0) \cdot C_0]$
- $C_1 = G_0 + P_0 \cdot C_0 = A_0 \cdot B_0 + (A_0 + B_0) \cdot C_0$
- $C_2 = G_1 + P_1 \cdot C_1 = A_1 \cdot B_1 + (A_1 + B_1) \cdot A_0 \cdot B_0 + (A_1 + B_1) \cdot (A_0 + B_0) \cdot C_0$
- $C_3 = G_2 + P_2 \cdot C_2 = A_2 \cdot B_2 + (A_2 + B_2) \cdot A_1 \cdot B_1 + (A_2 + B_2) \cdot (A_1 + B_1) \cdot A_0 \cdot B_0 + (A_2 + B_2) \cdot (A_1 + B_1) \cdot (A_0 + B_0) \cdot C_0$

### Q22

Suppose the processor has a directed-mapped cache, and te physical addresses of its memory is 28-bit. The cache has 8 cache lines of 64 bytes each. What are the number of bits in the tag, index, and offset fields of the physical address?

Solution:

- Each cache line has 64 bytes, so the offset field has 6 bits.
- There are 8 cache lines, so the index field has 3 bits.
- The remaining 19 bits are the tag field.

### Q23

Write a MIPS assembly program to read 3 integers from the keyboard, and print the 3 integers in descending order.

Example:

Input
```
3
4
2
```

Output
```
4
3
2
```

Solution:

```asm
.text
main:
    # Read 3 integers from the keyboard
    li $v0, 5
    syscall
    move $t0, $v0
    li $v0, 5
    syscall
    move $t1, $v0
    li $v0, 5
    syscall
    move $t2, $v0

    # if (t0 < t1) swap(t0, t1)
    slt $t3, $t0, $t1
    beq $t3, $zero, branch1 # if t0 >= t1
    move $a0, $t0
    move $a1, $t1
    jal swap
    move $t0, $v0
    move $t1, $v1

    # if (t0 < t2) swap(t0, t2)
branch1:
    slt $t3, $t0, $t2
    beq $t3, $zero, branch2 # if t0 >= t2
    move $a0, $t0
    move $a1, $t2
    jal swap
    move $t0, $v0
    move $t2, $v1

    # if (t1 < t2) swap(t1, t2)
branch2:
    slt $t3, $t1, $t2
    beq $t3, $zero, end # if t1 >= t2
    move $a0, $t1
    move $a1, $t2
    jal swap
    move $t1, $v0
    move $t2, $v1

end:
    # Print the 3 integers in descending order
    li $v0, 1
    move $a0, $t0
    syscall
    li $v0, 11
    li $a0, 10 # '\n'
    syscall
    li $v0, 1
    move $a0, $t1
    syscall
    li $v0, 11
    li $a0, 10
    syscall
    li $v0, 1
    move $a0, $t2
    syscall
    j exit

swap:
    move $v1, $a0
    move $v0, $a1
    jr $ra

exit:
    li $v0, 10
    syscall
```

## Q24

| Substraction | $D_3D_2D_1D_0$ | $B_{out}$ |
| ------ | -------------- | --------- |
| 0 | 0000 | 0 |
| 0-1 (0001) | 0001 | 1 |
| 0-2 (0010) | 0011 | 1 |
| 0-3 (0011) | 0010 | 1 |
| 0-4 (0100) | 0111 | 1 |
| 0-5 (0101) | 0110 | 1 |
| 0-6 (0110) | 0100 | 1 |
| 0-7 (0111) | 0101 | 1 |
| 0-8 (1000) | 1111 | 1 |

(c) Given a full substractor: $SUB(X, Y, B_{in}) = (D, B_{out})$, where $D = X - Y - B_{in}$, $B_{out} = 1$ if $D < 0$, otherwise $B_{out} = 0$. Please draw the logic circuit of a 4-bit full substractor $SUB_4(X_3X_2X_1X_0, Y_3Y_2Y_1Y_0) = (D_3D_2D_1D_0, B_{out})$.

(omitted)

(d) Use $SUB$ and $SUB_4$ implemented above, to implement an 4-bit adder $ADD_4(X_3X_2X_1X_0, Y_3Y_2Y_1Y_0) = (S_3S_2S_1S_0, B_{out})$ where $X$ and $Y$ are signed numbers in 2's complement representation.

Solution:

Since $X + Y = X - (-Y)$, we can:

1. Negate $Y$ by flipping all bits and adding 1 (same to 2's complement).
2. Compute $X - (-Y)$ using $SUB_4$.

Consider in a context of adder, 2's complement is performed by negating all bits, and adding 1 use 4-bit full adder.

Because the 4-bit substractor is unsigned, we can simply perform $SUB_4(1, Y, 0)$ to negate $Y$.
