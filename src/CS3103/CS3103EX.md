
Problems from CS3103 2021B Final Exam

```
1. [1 mark] 
Comparing with uniprogramming, multiprogramming generally achieves ________ throughput and 
________ resource utilization. 
a) higher, higher 
b) higher, lower 
c) lower, higher 
d) lower, lower 
```

Answer: a

```
2. [1 mark] 
Which of the following event(s) may take a process to a ready state? 
(i) A process is newly created 
(ii) Timeout of a running process 
(iii) An I/O event a process waiting for occurs 
(iv) Swap a process from disk into main memory 
a) (ii) and (iii) 
b) (i), (ii) and (iii) 
c) (ii) only 
d) All of the above 
```

Answer: d

States of a process: New, Ready, Running, Waiting, Terminated

(i) New -> Ready

(ii) Running -> Ready

(iii) Waiting -> Ready

(iv) Ready

```
3. [1 mark] 
Which of the following about a suspended process must be wrong? 
a) Not immediately available for execution 
b) Not waiting on an event. 
c) Waiting on an event in main memory. 
d) Suspended by its parent process. 
```

Answer: c

It can be waiting on an event in secondary memory (i.e. waiting for I/O), but not in main memory.

```
4. [1 mark] 
Which of the following is a possible description of the program output? 
 main() 
 { int pid; 
 pid = fork(); 
 printf(“%d ”, pid); 
 } 
a) Two positive integers 
b) Two ‘0’s 
c) One positive integer 
d) A ‘0’ followed by a positive integer 
```

Answer: d

Since child must exit before parent can continue, the child will print 0 first, then the parent will print the child's pid.

```
5. [3 marks] 
How many times does the following program print CS3103? 
main( ) 
{ int i; 
for (i=0; i<3; i++) 
fork( ); 
printf(“CS3103\n”); 
} 
```

Answer: 8

All processes (they are named in `parent-i` format, where `i` is the iteration number that created the process):

- main
    - main-1
        - main-1-2
            - main-1-2-3
        - main-1-3
    - main-2
        - main-2-3
    - main-3

General rule: `2^n` processes are created by a loop that runs `n` times.


```
6. [1 mark] 
What characteristics are observed while going up the memory hierarchy? 
(i) increasing cost per bit 
(ii) increasing capacity 
(iii) increasing access time 
(iv) increasing frequency of access to the memory by the processor 
a) (i), (iii) and (iv) 
b) (i) and (iv) 
c) (ii) and (iii) 
d) All of the above 
```

Answer: b

```
7. [1 mark] 
____ , which refers to the tendency of execution to involve a number of memory locations 
that are clustered, can be exploited by using ____ cache blocks. 
a) Temporal locality, recently used 
b) Temporal locality, frequently used 
c) Spatial locality, small 
d) Spatial locality, large 
```

Answer: Spatial locality, small

For spatial locality, large cache blocks are used. Small cache blocks result in high miss rates.

```
8. [1 mark] 
Which of the following is/are disadvantages of kernel-level threads (KLTs)? 
(i) The kernel cannot simultaneously schedule multiple threads from the same process on 
multiple processors. 
(ii) If a thread of a process gets blocked, the whole process blocks. 
(iii) The transfer of control from one thread to another within the same process requires a 
mode switch to the kernel and so is time consuming. 
(iv) Creation and destruction of threads in the kernel is costlier. 
a) (iii) and (iv) 
b) (iii) only 
c) (i) and (ii) 
d) (i) and (iii) 
```

Answer: a

```
9. [1 mark] 
Which of the following statements about multithreading is false? 
a) Threads of the same process can share the same memory. 
b) Thread creation is much faster than process creation. 
c) Inter-process communication is more efficient than communication between threads. 
d) On multiprocessor systems, multithreading takes advantage of the additional hardware, thus 
resulting in better overall performance.
```

Answer: c

```
10. [2 marks] 
Consider a memory system with cache access time of 0.1 µs and memory access time (time needed to 
load a word into the cache) of 1 µs. If the hit ratio is 0.9, what is the average time to access a word? 
a) 0.15 µs 
b) 0.19 µs 
c) 0.20 µs 
d) 1.01 µs
```

Answer: b

$t = \alpha \times t_{\text{cache}} + (1 - \alpha) \times t_{\text{memory}} = 0.9 \times 0.1 + 0.1 \times 1 = 0.19$

```
11. [2 marks] 
Three processes, P0, P1 and P2 are competing for three resources, X, Y, Z. Which of the following 
request sequence can prevent deadlock? 
a) P0: request(X); P1: request(Z); P2: request(X); P0: request(Z); P1: request(Y); P2: request(Y) 
b) P0: request(X); P1: request(Z); P2: request(Y); P0: request(Z); P1: request(Y); P2: request(X) 
c) P0: request(Z); P1: request(Y); P2: request(X); P0: request(X); P1: request(Z); P2: request(Y) 
d) None of the above 
```

Answer: a

Since each resource type only has one instance, deadlock can be checked by constructing a resource allocation graph. If the graph has a cycle, deadlock is present.

For the first time a resource is requested, use an assignment edge. For subsequent requests, use a request edge.

A has no cycles. The safe sequence is P1 → P0 → P2.

B has a cycle: P2 → P1 → P0 → P2.

C has a cycle: P0 → P2 → P1 → P0.

```
12. [2 marks] 
If there are three processes and ten identical resources in the system, to ensure that deadlock will 
never occur, what is the maximum number of resources each process could request, if all processes 
must have the same maximum number of resources? 
```

Answer: 3

```
13. [1 mark] 
When several threads access shared information in main memory, mutual exclusion must be enforced. 
a) True 
b) False 
```

Answer: b

Multiple readers can access shared information concurrently without any issues.

```
14. [1 mark] 
Which of the following statements about achieving mutual exclusion using semaphore is false? 
a) A thread performs the semSignal operation when it exits its critical section. 
b) A thread, which performs the semWait operation and sets the semaphore value to 0, can enter 
its critical section. 
c) The semaphore is initialized to 1. 
d) None of the above. 
```

Answer: b

Should be "reduces the semaphore value by 1".

```
15. [1 mark] 
Which of the following statements about binary semaphore and mutex is true? 
a) A binary semaphore may be initialized to any non-negative integer value. 
b) A mutex can be locked and unlocked by different processes. 
c) A binary semaphore can always be replaced by a mutex. 
d) None of the above 
```

Answer: d

a: Binary semaphores can only be 0 or 1.

b: A mutex can only be unlocked by the process that locked it.

c: Mutex is not semantically equivalent to a binary semaphore. Mutex is for enforcing mutual exclusion, while a binary semaphore is for signalling.

```
16. [1 mark] 
The solution to the Dining Philosophers problem must ________. 
a) prevent deadlock 
b) prevent starvation 
c) ensure mutual exclusion 
d) all of the above
```

Answer: d

```
17. [1 mark] 
Long-term scheduling is used to determine _____. 
a) when and which new process is admitted to the ready queue. 
b) whether a process is swapped to main memory. 
c) which ready process to execute next 
d) None of the above 
```

Answer: a

Long-term scheduling is for selecting processes from the job queue to the ready queue.

Short-term scheduling is for selecting the next process to run.

```
18. [1 mark] 
Among the following scheduling algorithms, _______ is preemptive. 
a) FCFS (First-Come-First-Served)
b) SPN (Shortest Process Next)
c) HRRN (Highest Response Ratio Next)
d) None of the above 
```

Answer: c

```
19. [2 marks] 
Select all scheduling policy(ies) that favour CPU bound jobs over I/O bound jobs. 
a) Round Robin 
b) FCFS 
c) SPN 
d) Feedback 
```

Answer: b, d

- FCFS is non-preemptive, so CPU-bound jobs will run to completion.
- Feedback scheduling will increase the priority of CPU-bound jobs.
- SPN favours I/O-bound jobs as they have shorter CPU bursts.

```
20. [1 mark] 
Among the following processor scheduling algorithms, ________ requires the estimation of the 
expected service time. 
a) RR 
b) Feedback 
c) FCFS 
d) HRRN 
```

Answer: d

```
21. [1 mark] 
For Round Robin scheduling, when the time slice is too large, Round Robin is equivalent to 
_____________ scheduling algorithm. 
```

Answer: FCFS

```
22. [2 marks] 
Suppose the ready queue is empty while 4 jobs arrive at the same time. Each job’s service time is 2 
minutes. With the FCFS scheduling policy, what is the average turnaround time? 
```

Answer: 5

Turnaround time = Completion time - Arrival time

$\frac{2 + 4 + 6 + 8}{4} = 5$

```
23. [3 marks] 
Consider the following five processes in the table that need to be scheduled. If SPN is used, what is 
the average turnaround time of the five processes? 
Process arrival time service time 
 P1 0.0 9 
 P2 0.4 4 
 P3 1.0 1 
 P4 5.5 4 
 P5 7 2
```

- t=0~9: P1
- t=9~10: P3
- t=10~12: P5
- t=12~16: P2
- t=16~20: P4

| Process | Arrival time | Completion time | Turnaround time |
|---------|--------------|-----------------|-----------------|
| P1 | 0.0 | 9 | 9 |
| P2 | 0.4 | 16 | 15.6 |
| P3 | 1.0 | 10 | 9 |
| P4 | 5.5 | 20 | 14.5 |
| P5 | 7 | 12 | 5 |

Average turnaround time = $\frac{9 + 15.6 + 9 + 14.5 + 5}{5} = 10.62$

```
24. [1 mark] 
The correct description about ‘memory protection’ is _______ 
a) Prevent hardware memory from damaging 
b) Prevent our program from losing data 
c) Ensure processes should not be able to reference memory locations in another process without 
permission. 
d) Prevent the program from being swapped
```

Answer: c

```
26. [3 marks] 
Suppose we have the following page access stream: 5 0 1 2 0 3 0 4 2 3 0 for a system with four frames 
which are empty at the beginning. Using the least recently used (LRU) page replacement policy, find 
the number of page faults for the given reference string, assuming that before the frame allocation is 
initially filled, all first unique pages are also counted as page faults. 
```

Answer: 6

| Page Reference | Frames | Page Faults |
|----------------|--------|-------------|
| 5 | 5,-,-,- | 1 |
| 0 | 5,0,-,- | 2 |
| 1 | 5,0,1,- | 3 |
| 2 | 5,0,1,2 | 4 |
| 0 | 5,1,2,0 | 4 |
| 3 | 1,2,0,3 | 5 |
| 0 | 1,2,3,0 | 5 |
| 4 | 2,3,0,4 | 6 |
| 2 | 3,0,4,2 | 6 |
| 3 | 0,4,2,3 | 6 |
| 0 | 4,2,3,0 | 6 |

```
27. [2 marks] 
Assuming that the rotational speed of the disk is 3000 rpm and the disk surface is divided into 10 
sectors, what is the transfer time of one sector? 
```

Answer: 0.002 s

Time to rotate a full circle = $\frac{1}{3000} \times 60 = 0.02$ s

Time to rotate one sector = $\frac{0.02}{10} = 0.002$ s

```
28. [1 mark] 
Thrashing occurs when ________ 
a) Inadequate resident set leads to frequent process swapping 
b) The scheduler flip-flops between two processes, leading to the starvation of others. 
c) Two or more processes compete for the same region of shared memory and wait on mutex 
locks. 
d) Multiple processes execute in the same address space. 
```

Answer: a

Thrashing: The process's working set in memory is too small, so the process is constantly swapping pages in and out of memory.

Convoy effect: The scheduler flip-flops between two processes, leading to the starvation of others.

Deadlock: Two or more processes compete for the same region of shared memory and wait on mutex locks.

```
1. Mutual Exclusion and Synchronization:
Consider the following solution to the readers/writers problem using message passing. 
Suppose the variable count is initialized to 100 and all the mailboxes in the system are initially 
empty. Consider that the following three processes come to the system to read/write the shared file in 
the sequence described in part (i) to (iii) below. 
```

| Process name | Function call |
| ------------ | ------------- |
| Reader1 | `reader(1)` |
| Reader2 | `reader(2)` |
| Writer3 | `writer(3)` |

```c
void reader(int i) {
    message rmsg;
    while (true) {
        rmsg = i;
        send(readrequest, rmsg);
        receive(mbox[i], rmsg);
        READUNIT();
        rmsg = i;
        send(finished, rmsg);
    }
}

void writer(int i) {
    message wmsg;
    while (true) {
        wmsg = i;
        send(writerequest, wmsg);
        receive(mbox[i], wmsg);
        WRITEUNIT();
        wmsg = i;
        send(finished, wmsg);
    }
}

void controller() {
    while (true) {
        if (count > 0) {
            if (!empty(finished)) {
                receive(finished, msg);
                count++;
            } else if (!empty(writerequest)) {
                receive(writerequest, msg);
                writer_id = msg.id;
                count = count - 100;
            } else if (!empty(readrequest)) {
                receive(readrequest, msg);
                count--;
                send(msg.id, "OK");
            }
        }
        if (count == 0) {
            send(writer_id, "OK");
            receive(finished, msg);
            count = 100;
        }
        while (count < 0) {
            receive(finished, msg);
            count++;
        }
    }
}
```

Understand the code:

`reader` and `writer` are the reader and writer processes. They send a request to the controller, then wait for a response at their mailbox.

`controller` achieves mutual exclusion. Meaning of `count`:

- If count = 100, the file is ready for writing.
- If count = 0, there is no reader or writer. The controller informs the writer to write and set count to 100.
- If count < 0, there are readers. The absolute value of count is the number of readers. Writer cannot write until all readers finish.

```
(i) [4 marks]
Firstly, Reader1 wants to read the file. List all the messages passing through the mailboxes, which 
contains process name, action, message content and mailbox name, to illustrate how Reader1 can read 
the file. Also show any change of the value of the variable count. The first two steps are shown 
below as examples. 
count = 100 
Reader1 sends rmsg=1 to readrequest 
Reader1 blocks on receive message from mbox[1] 
```

- count = 100
- Reader1 sends rmsg=1 to readrequest
- Reader1 blocks on receive message from mbox[1]
- Controller receives msg=1 from readrequest
- count = 99
- Controller sends "OK" to Reader1
- Reader1 receives "OK" from mbox[1]
- Reader1 sends rmsg=1 to finished
- Controller receives msg=1 from finished
- count = 100

```
(ii) [2 marks] 
Secondly, Reader2 wants to read the file while Reader1 is still reading the file. List all the messages 
passing through the mailboxes and the values of count to illustrate how both readers can read the 
file simultaneously. 
```

- count = 100
- Reader1 sends rmsg=1 to readrequest, Reader2 sends rmsg=2 to readrequest
- Reader1 blocks on receive message from mbox[1], Reader2 blocks on receive message from mbox[2]
- Controller receives msg=1 from readrequest
- count = 99
- Controller sends "OK" to Reader1
- Controller receives msg=2 from readrequest
- count = 98
- Controller sends "OK" to Reader2
- Reader1 receives "OK" from mbox[1], Reader2 receives "OK" from mbox[2]
- Reader1 sends rmsg=1 to finished, Reader2 sends rmsg=2 to finished
- Controller receives msg=1 from finished
- count = 99
- Controller receives msg=2 from finished
- count = 100

```
(iii) [6 marks] 
Lastly, Writer3 wants to write while the two readers are still reading the file. List all the messages 
passing through the mailboxes and the values of count until all the three processes are done to 
illustrate how mutual exclusion is achieved. 
```

- count = 98
- Writer3 sends wmsg=3 to writerequest
- Writer3 blocks on receive message from mbox[3]
- Controller receives msg=3 from writerequest
- count = -2
- Reader1 sends rmsg=1 to finished, Reader2 sends rmsg=2 to finished
- Controller receives msg=1 from finished
- count = -1
- Controller receives msg=2 from finished
- count = 0
- Controller sends "OK" to Writer3
- Controller blocks on receive message from finished
- Writer3 receives "OK" from mbox[3]
- Writer3 sends wmsg=3 to finished
- Controller receives msg=3 from finished
- count = 100

```
2. Deadlock
(i) [8 marks]
A system has four processes and five resources. The Claim matrix, current Allocation matrix and the 
current Available vector are as follows.
```

| Process | Max | Allocation |
|---------|-----|------------|
| A | 1 1 2 1 3 | 1 0 2 1 1 |
| B | 1 1 2 2 1 | 1 1 1 1 0 |
| C | 2 1 3 1 0 | 1 1 0 1 0 |
| D | 2 2 2 1 1 | 2 0 1 1 1 |

| Available |
|-----------|
| 0 0 x 1 1 |

```
What is the smallest value of x for which this is a safe state? Explain and show the steps clearly. 
```

- Need[A] = Max[A] - Allocation[A] = 0 1 0 0 2
- Need[B] = Max[B] - Allocation[B] = 0 0 1 0 1
- Need[C] = Max[C] - Allocation[C] = 1 0 3 0 0
- Need[D] = Max[D] - Allocation[D] = 0 2 1 0 0

Observe that only Need[B] is possible to be satisfied. Let x = 1.

Using Banker's algorithm:

- Need[B] = 0 0 1 0 1 <= Work = Available = 0 0 1 1 1
    - B finishes, Work += Allocation[B] = 1 1 2 2 1

We observe that no other process can finish. But if increase x to 2, then C can finish.

- Need[B] = 0 0 1 0 1 <= Work = Available = 0 0 2 1 1
    - B finishes, Work += Allocation[B] = 1 1 3 2 1
- Need[C] = 1 0 3 0 0 <= Work = 1 1 3 2 1
    - C finishes, Work += Allocation[C] = 2 2 3 3 1
- Need[D] = 0 2 1 0 0 <= Work = 2 2 3 3 1
    - D finishes, Work += Allocation[D] = 4 2 4 4 2
- Need[A] = 0 1 0 0 2 <= Work = 4 2 4 4 2
    - A finishes, Work += Allocation[A] = 5 2 6 5 3

```
(ii) [4 marks]
Consider a system with five processes P0 through P4 and three resource types A, B, and C. Resource 
type A has 5 instances, resource type B has 3 instances and resource type C has 5 instances. Given the 
following system state, apply the deadlock detection algorithm to check whether deadlock has 
occurred or not. If yes, which processes are deadlocked? Show the steps clearly.
```

| Process | Allocation | Request |
|---------|------------|---------|
| P0 | 0 2 0 | 3 0 0 |
| P1 | 0 0 0 | 2 0 2 |
| P2 | 0 0 3 | 0 2 0 |
| P3 | 0 1 0 | 1 0 0 |
| P4 | 3 0 2 | 0 0 1 |

| Available |
|-----------|
| 2 0 0 |

- Request[P3] = 1 0 0 <= Work = Available = 2 0 0
    - P3 finishes, Work += Allocation[P3] = 2 1 0

Since no other process requests can be satisfied (request[i] <= work), no other process can finish. Therefore, deadlock has occurred.

Deadlocked processes: P0, P1, P2, P4

```
Disk Scheduling
(i) [8 marks]
Given a hard disk of 1000 tracks (Track 0-999). Write down the track numbers that the disk head will 
travel for the following 4 disk scheduling algorithms, FIFO, SSTF, SCAN, and C-SCAN, with the 
following sequence of disk track requests: 123, 874, 692, 475, 105, 376. The disk head is starting at 
track 345, in the direction of moving towards track 0.
```

- FIFO: 345 123 874 692 475 105 376
- SSTF: 345 376 475 692 874 123 105
- SCAN: 345 123 105 0 376 475 692 874
- C-SCAN: 345 123 105 0 999 874 692 475 376
- C-LOOK: 345 123 105 376 475 692 874

```
(ii) [4 marks]
Select the most effective disk scheduling algorithm(s) (FIFO, SSTF, SCAN, C-SCAN) for the request 
sequence in part (i) in terms of the total number of tracks travelled. Explain your answer by 
comparing the total number of tracks travelled for each algorithm.
```

- FIFO: 2013
- SSTF: 1298
- SCAN: 1219
- C-SCAN: 1776

SCAN is the most effective.

```
Memory
The following paging system has 64KB main memory, which is divided into 16 frames (frame 
numbers are from 0 to 15). Suppose the process A has 4 pages. The page numbers are 0, 1, 2, and 3, 
which are loaded to frame 9, 0, 1, and 14, respectively. 
(i) [2 marks] 
What is the length of process A? 
(ii) [4 marks] 
For logical addresses 0001 0000 0100 1000 and 0011 0000 0110 0011 (all logical addresses are 
binary values), convert them to the physical address in the main memory.
```

- Physical memory: 64KB
- Physical frame: 16
- Page size = Frame size = 64KB / 16 = 4KB
- Virtual address space: 16 bits = $2^{16}$ = 64KB
- Virtual page: 64KB / 4KB = 16
- VPN: 4 bits
- Offset: 12 bits

(i) Length of process A = 4 pages * 4KB = 16KB

(ii)

Page Table:

| VPN | PFN |
|-----|-----|
| 0b0000 | 0b1001 |
| 0b0001 | 0b0000 |
| 0b0010 | 0b0001 |
| 0b0011 | 0b1110 |

- VA 0001 0000 0100 1000 = PA 0000 0000 0100 1000 = 0x0048
- VA 0011 0000 0110 0011 = PA 1110 0000 0110 0011 = 0xE063

```
(iii) [6 marks]
Suppose three page frames are assigned to a process and they are initially empty. Before the frame 
allocation is initially filled, all first unique pages are also counted as page faults. 
Complete the table below if we use the CLOCK replacement algorithm. 
```

Legends:

- `*` indicates the use bit is 1.
- `->` indicates the current position of next frame pointer.

SCR (Second Chance Replacement) Algorithm:

| Request | Frame 1 | Frame 2 | Frame 3 | Page Faults |
|---------|---------|---------|---------|-------------|
| 1 | 1 | -> | - | 1 |
| 4 | 1 | 4 | -> | 2 |
| 3 | -> 1 | 4 | 3 | 3 |
| 1 | -> 1* | 4 | 3 | 3 |
| 2 | 1 | 2 | -> 3 | 4 |
| 3 | 1 | 2 | -> 3* | 4 |
| 1 | 1* | 2 | -> 3* | 4 |
| 4 | 1 | 4 | -> 3 | 5 |
| 3 | 1 | 4 | -> 3* | 5 |

CLOCK Algorithm:

| Request | Frame 1 | Frame 2 | Frame 3 | Page Faults |
|---------|---------|---------|---------|-------------|
| 1 | 1* | -> | - | 1 |
| 4 | 1* | 4* | -> | 2 |
| 3 | -> 1* | 4* | 3* | 3 |
| 1 | -> 1* | 4* | 3* | 3 |
| 2 (i) | -> 1 | 4 | 3 | 3 |
| 2 (ii) | 2* | -> 4 | 3 | 4 |
| 3 | 2* | -> 4 | 3* | 4 |
| 1 | 2* | 1* | -> 3* | 5 |
| 4 (i) | 2 | 1 | -> 3 | 5 |
| 4 (ii) | -> 2 | 1 | 4* | 6 |
| 3 | 3* | -> 1 | 4* | 7 |

---

Questions from University of California, Berkeley CS162 Fall 2012 Midterm Exam

```
1. (24 points total) True/False and Why? CIRCLE YOUR ANSWER. For each 
question: 1 point for true/false correct, 2 point for explanation. An explanation cannot 
exceed 2 sentences.
a) Each thread has its own stack.
b) Starvation implies deadlock.
c) It’s generally possible to substitute a semaphore for a condition variable, because 
sem.V()/sem.P() have similar semantics to cond.signal()/cond.wait().
d) Shortest Run Time First (SRTF) is the “optimal” scheduling algorithm, but it is 
generally not implemented directly, due to excessive context switching overhead.
e) Using a smaller page size increases the size of the page table.
f) Moving from a single level page table to a two-level page table will always 
decrease the memory footprint (in aggregate) used by the page table. 
g) Unlike paging, segmentation doesn’t prevent processes from accessing physical 
memory not allocated to them.
h) If you increase the size of a the page cache from 8Kb to 16Kb, and you are 
running a “Perfect LRU” page replacement strategy, the cache hit ratio will never 
get worse.
```

a. TRUE. The thread is the unit of execution, and it uses the stack to store return addresses and arguments.

b. FALSE. A system may exit from starvation, but not deadlock.

c. FALSE. They are semantically different:

- Condition variable is not communicative (calling `cond.signal()` before `cond.wait()` has no effect, but `sem.V()` before `sem.P()` will increment the semaphore).
- Semaphores has no nition of implicit locks (condition variables must be used with a mutex).

d. FALSE. SRTF is not implemented due to it is impossible to predict the future.

e. TRUE. A smaller page size will increase the number of pages, and thus the size of the page table.

f. FALSE. A two-level page table will increase the memory footprint due to the additional level of indirection. (2-level page table includes all the pages in the first level)

g. FALSE. Segmentation avoid access to unallocated memory by checking the segment bounds.

h. TRUE. With 16Kb cache, the pages in cache is a superset of the 8Kb cache, so the hit ratio will not decrease.

```
2. Memory hierarch: You are responsible for designing the memory system 
for a byte addressable system. The virtual memory address space is 32 bits and the 
physical memory address space is 16 bits. 
a) (4 points) Assume the system uses a two level page table to translate a virtual 
address to a physical address. Show the format of the virtual address, specify the 
page size (pick one size if multiple sizes are feasible), and specify the length of 
each field in the virtual address. Make sure that each translation table fits in a 
page. 
```

Assume PDE index has $b$ bits, PTE index has $b$ bits, and offset has $c$ bits.

Then

- The length of the virtual address is $32$ bits → $32 = b + b + c$.
- Each translation table fits in a page: $2^b \times 4 \leq 2^c$ bytes (each entry is 32 bits = 4 bytes).

Therefore $b = 10, c = 12$.

The scheme is as follows:

- Bit 31-22: PDE index
- Bit 21-12: PTE index
- Bit 11-0: Offset

```
c) (3 points) The main memory access time is 100ns, and the cache lookup time is 
50ns. Assuming a cache hit rate of 90%, what is the average time to read a 
location from main memory? (Note: Assume the cache hit rate is the same for the 
data and the page translation tables.)
```

$t_0 = \alpha \times t_{\text{cache}} + (1 - \alpha) \times (t_{\text{cache}} + t_{\text{memory}}) = 0.9 \times 50 + 0.1 \times (50 + 100) = 60$ ns.

Note cache access and memory access are NOT parallel; memory access only occurs if there is a cache miss.

Additionally, read a location from main memory is completed in 3 steps:

- Read PT from cache or memory
- Read PFN from cache or memory
- Read value from cache or memory

Therefore the total time is $t_1 = 3 \times 60 = 180$ ns.

```
d) (3 points) To speed up the address translation process we introduce a TLB that 
has an access time of 20ns. Assuming the TLB hit rate is 95%, what is the average 
access time for a memory operation?
```

$t = \alpha \times (t_{\text{TLB}} + t_0) + (1 - \alpha) \times (t_{\text{TLB}} + t_1) = 0.95 \times (20 + 60) + 0.05 \times (20 + 180) = 86$ ns.

The point of TLB is to directly translate VPN to PFN without going through the page table.

If TLB hit, it still needs to read the value from memory, which takes 60ns.

If TLB miss, it needs to complete the 3-step process, which takes 180ns.

```
3. (12 points) Synchronization: A common parallel programming pattern is to perform 
processing in a sequence of parallel stages: all threads work independently during each 
stage, but they must synchronize at the end of each stage at a synchronization point called 
a barrier. If a thread reaches the barrier before all other threads have arrived, it waits. 
When all threads reach the barrier, they are notified and can begin the execution on the 
next phase of the computation. 
Example: 
while (true) {
 Compute stuff; 
 BARRIER(); 
 Read other threads results; 
}
a) (4 points) The following implementation of Barrier is incomplete and has two 
lines missing. Fill in the missing lines so that the Barrier works according to the 
prior specifications.
```

```c
class Barrier() { 
    int numWaiting = 0; // Initially, no one at barrier
    int numExpected = 0; // Initially, no one expected
    Lock L = new Lock();
    ConditionVar CV = new ConditionVar();
    void threadCreated() { 
        L.acquire(); 
        numExpected++; 
        L.release(); 
    }
    void enterBarrier() { 
        L.acquire(); 
        numWaiting++; 
        if (numExpected == numWaiting) { // If we are the last
        numWaiting = 0; // Reset barrier and wake threads
            // Fill me in
        } else { // Else, put me to sleep
            // Fill me in 
        } 
        L.release() ;
    } 
}
```

Answer:

```c
    if (numExpected == numWaiting) { // If we are the last
        numWaiting = 0; // Reset barrier and wake threads
        CV.broadcast();
    } else { // Else, put me to sleep
        CV.wait(L);
    }
```
